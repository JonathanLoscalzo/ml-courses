{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Training a neural network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why updating the model?\n",
    "- Better results on your specific domain\n",
    "- Learn classification schemes specifically for your problem\n",
    "- Essential for text classification\n",
    "- Very useful for named entity recognition\n",
    "- Less critical for part-of-speech tagging and dependency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How training works (1)\n",
    "1. Initialize the model weights randomly with nlp.begin_training\n",
    "1. Predict a few examples with the current weights by calling nlp.update\n",
    "1. Compare prediction with true labels\n",
    "1. Calculate how to change weights to improve predictions\n",
    "1. Update weights slightly\n",
    "1. Go back to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How training works (2)\n",
    "- Diagram of the training process\n",
    "- Training data: Examples and their annotations.\n",
    "- Text: The input text the model should predict a label for.\n",
    "- Label: The label the model should predict.\n",
    "- Gradient: How to change the weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Training the entity recognizer\n",
    "- The entity recognizer tags words and phrases in context\n",
    "- Each token can-  only be part of one entity\n",
    "- Examples need to come with context\n",
    "```\n",
    "(\"iPhone X is coming\", {'entities': [(0, 8, 'GADGET')]})\n",
    "```\n",
    "- Texts with no entities are also important\n",
    "```\n",
    "(\"I need a new phone! Any tips?\", {'entities': []})\n",
    "```\n",
    "- Goal: teach the model to generalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The training data\n",
    "- Examples of what we want the model to predict in context\n",
    "- Update an existing model: a few hundred to a few thousand examples\n",
    "- Train a new category: a few thousand to a million examples\n",
    "- spaCy's English models: 2 million words\n",
    "- Usually created manually by human annotators\n",
    "- Can be semi-automated – for example, using spaCy's Matcher!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.lang.en import English\n",
    "\n",
    "with open(\"static/iphone.json\") as f:\n",
    "    TEXTS = json.loads(f.read())\n",
    "\n",
    "nlp = English()\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Two tokens whose lowercase forms match 'iphone' and 'x'\n",
    "pattern1 = [{\"LOWER\": 'iphone'}, {\"LOWER\": 'x'}]\n",
    "\n",
    "# Token whose lowercase form matches 'iphone' and an optional digit\n",
    "pattern2 = [{\"LOWER\": 'iphone'}, { 'IS_DIGIT': True, \"OP\": \"?\"}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "matcher.add(\"GADGET\", None, pattern1, pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iPhone X, iPhone]\n",
      "[iPhone X, iPhone]\n",
      "[iPhone X, iPhone]\n",
      "[iPhone, iPhone 8]\n",
      "[iPhone]\n",
      "[]\n",
      "('How to preorder the iPhone X', {'entities': [(20, 28, 'GADGET'), (20, 26, 'GADGET')]})\n",
      "('iPhone X is coming', {'entities': [(0, 8, 'GADGET'), (0, 6, 'GADGET')]})\n",
      "('Should I pay $1,000 for the iPhone X?', {'entities': [(28, 36, 'GADGET'), (28, 34, 'GADGET')]})\n",
      "('The iPhone 8 reviews are here', {'entities': [(4, 10, 'GADGET'), (4, 12, 'GADGET')]})\n",
      "('Your iPhone goes up to 11 today', {'entities': [(5, 11, 'GADGET')]})\n",
      "('I need a new phone! Any tips?', {'entities': []})\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DATA = []\n",
    "\n",
    "# Create a Doc object for each text in TEXTS\n",
    "for doc in nlp.pipe(TEXTS):\n",
    "    # Match on the doc and create a list of matched spans\n",
    "    spans = [doc[start:end] for match_id, start, end in matcher(doc)]\n",
    "    print(spans)\n",
    "    # Get (start character, end character, label) tuples of matches\n",
    "    entities = [(span.start_char, span.end_char, \"GADGET\") for span in spans]\n",
    "    # Format the matches as a (doc.text, entities) tuple\n",
    "    training_example = (doc.text, {\"entities\": entities})\n",
    "    # Append the example to the training data\n",
    "    TRAINING_DATA.append(training_example)\n",
    "\n",
    "print(*TRAINING_DATA, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The steps of a training loop\n",
    "- Loop for a number of times.\n",
    "- Shuffle the training data.\n",
    "- Divide the data into batches.\n",
    "- Update the model for each batch.\n",
    "- Save the updated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.pipe_names, nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating an existing model\n",
    "- Improve the predictions on new data\n",
    "- Especially useful to improve existing categories, like PERSON\n",
    "- Also possible to add new categories\n",
    "- Be careful and make sure the model doesn't \"forget\" the old ones\n",
    "\n",
    "```\n",
    "# Loop for 10 iterations\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        print(texts, annotations)\n",
    "        nlp.update(texts, annotations)\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(path_to_model)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a new pipeline from scratch\n",
    "```\n",
    "# Start with blank English model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add a new label\n",
    "ner.add_label('GADGET')\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Train for 10 iterations\n",
    "for itn in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Divide examples into batches\n",
    "    for batch in spacy.util.minibatch(examples, size=2):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ner']\n",
      "{'ner': 13.333332538604736}\n",
      "{'ner': 25.146877884864807}\n",
      "{'ner': 33.52562475204468}\n",
      "{'ner': 6.892914116382599}\n",
      "{'ner': 15.981010377407074}\n",
      "{'ner': 19.556943893432617}\n",
      "{'ner': 3.2705454602837563}\n",
      "{'ner': 6.5285542123019695}\n",
      "{'ner': 8.234125423361547}\n",
      "{'ner': 1.54903374746209}\n",
      "{'ner': 4.290305365080712}\n",
      "{'ner': 5.90817542761215}\n",
      "{'ner': 5.616827309131622}\n",
      "{'ner': 13.944963905960321}\n",
      "{'ner': 15.914044762554113}\n",
      "{'ner': 2.5698778703808784}\n",
      "{'ner': 6.481321446597576}\n",
      "{'ner': 9.146115079522133}\n",
      "{'ner': 2.071006953716278}\n",
      "{'ner': 3.934548668563366}\n",
      "{'ner': 5.221237783553079}\n",
      "{'ner': 0.9154163065832108}\n",
      "{'ner': 1.3927827711322607}\n",
      "{'ner': 2.7633928216837376}\n",
      "{'ner': 1.0691045480070898}\n",
      "{'ner': 1.108544173936025}\n",
      "{'ner': 1.1252407127994957}\n",
      "{'ner': 0.0021242555508251826}\n",
      "{'ner': 0.003405092637052576}\n",
      "{'ner': 2.2033404988185588}\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "TRAINING_DATA = [\n",
    "    ['How to preorder the iPhone X', {'entities': [[20, 28, 'GADGET']]}], \n",
    "    ['iPhone X is coming', {'entities': [[0, 8, 'GADGET']]}], \n",
    "    ['Should I pay $1,000 for the iPhone X?', {'entities': [[28, 36, 'GADGET']]}], \n",
    "    ['The iPhone 8 reviews are here', {'entities': [[4, 12, 'GADGET']]}], \n",
    "    ['Your iPhone goes up to 11 today', {'entities': [[5, 11, 'GADGET']]}], \n",
    "    ['I need a new phone! Any tips?', {'entities': []}]\n",
    "]\n",
    "\n",
    "# Create a blank 'en' model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create a new entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe('ner')\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "# Add the label 'GADGET' to the entity recognizer\n",
    "ner.add_label('GADGET')\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=2):\n",
    "        texts = [text for text, entities in batch]\n",
    "        annotations = [entities for text, entities in batch]\n",
    "\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations, losses=losses)\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is slowing down the iPhone 8 and iPhone X - how to stop it (iPhone 8, iPhone X)\n",
      "____________________\n",
      "I finally understand what the iPhone X ‘notch’ is for (iPhone X,)\n",
      "____________________\n",
      "Everything you need to know about the Samsung Galaxy S9 ()\n",
      "____________________\n",
      "Looking to compare iPad models? Here’s how the 2018 lineup stacks ()\n",
      "____________________\n",
      "The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple (iPhone 8, iPhone 8)\n",
      "____________________\n",
      "what is the cheapest ipad, especially ipad pro??? ()\n",
      "____________________\n",
      "Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics ()\n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "unseen_data = [\n",
    "    \"Apple is slowing down the iPhone 8 and iPhone X - how to stop it\",\n",
    "    \"I finally understand what the iPhone X ‘notch’ is for\",\n",
    "    \"Everything you need to know about the Samsung Galaxy S9\",\n",
    "    \"Looking to compare iPad models? Here’s how the 2018 lineup stacks\",\n",
    "    \"The iPhone 8 and iPhone 8 Plus are smartphones designed, developed, and marketed by Apple\",\n",
    "    \"what is the cheapest ipad, especially ipad pro???\",\n",
    "    \"Samsung Galaxy is a series of mobile computing devices designed, manufactured and marketed by Samsung Electronics\",\n",
    "]\n",
    "\n",
    "docs = nlp.pipe(unseen_data)\n",
    "for doc in docs:\n",
    "    print(doc, doc.ents)\n",
    "    print(20*\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Models can \"forget\" things\n",
    "Existing model can overfit on new data\n",
    "e.g.: if you only update it with WEBSITE, it can \"unlearn\" what a PERSON is\n",
    "Also known as \"catastrophic forgetting\" problem\n",
    "\n",
    "### Solution 1: Mix in previously correct predictions\n",
    "For example, if you're training WEBSITE, also include examples of PERSON\n",
    "Run existing spaCy model over data and extract all other relevant entities\n",
    "\n",
    "BAD:\n",
    "```\n",
    "TRAINING_DATA = [\n",
    "    ('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]})\n",
    "]\n",
    "```\n",
    "GOOD:\n",
    "```\n",
    "TRAINING_DATA = [\n",
    "    ('Reddit is a website', {'entities': [(0, 6, 'WEBSITE')]}),\n",
    "    ('Obama is a person', {'entities': [(0, 5, 'PERSON')]})\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Models can't learn everything\n",
    "- spaCy's models make predictions based on local context\n",
    "- Model can struggle to learn if decision is difficult to make based on context\n",
    "- Label scheme needs to be consistent and not too specific\n",
    "- For example: CLOTHING is better than ADULT_CLOTHING and CHILDRENS_CLOTHING\n",
    "    \n",
    "### Solution 2: Plan your label scheme carefully\n",
    "Pick categories that are reflected in local context\n",
    "More generic is better than too specific\n",
    "Use rules to go from generic labels to specific categories\n",
    "\n",
    "BAD:\n",
    "```\n",
    "LABELS = ['ADULT_SHOES', 'CHILDRENS_SHOES', 'BANDS_I_LIKE']\n",
    "```\n",
    "GOOD:\n",
    "```\n",
    "LABELS = ['CLOTHING', 'BAND']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Paris, Arkansas)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"There's also a Paris in Arkansas, lol\")\n",
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add(\"GPE\", None, *list(nlp(ent.text) for ent in doc.ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(384, 4, 5), (384, 6, 7)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your new spaCy skills\n",
    "- Extract linguistic features: part-of-speech tags, dependencies, named entities\n",
    "- Work with pre-trained statistical models\n",
    "- Find words and phrases using Matcher and PhraseMatcher match rules\n",
    "- Best practices for working with data structures Doc, Token Span, Vocab, Lexeme\n",
    "- Find semantic similarities using word vectors\n",
    "- Write custom pipeline components with extension attributes\n",
    "- Scale up your spaCy pipelines and make them fast\n",
    "- Create training data for spaCy' statistical models\n",
    "- Train and update spaCy's neural network models with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f14a1b65d30>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f14a1a562e8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f14a1a56348>)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitde7cbade5f3b409597a00bf77a4b8fa2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
